{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b090392-b5ef-410e-80ff-eda3b8fbb001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# エージェントを構築する\n",
    "言語モデル自体はアクションを実行できず、テキストを出力するだけです。LangChainの大きなユースケースはエージェントの作成です。[エージェント](https://python.langchain.com/docs/concepts/agents/)は、[LLM](https://python.langchain.com/docs/concepts/chat_models/)を推論エンジンとして使用し、実行するアクションと必要な入力を決定するシステムです。アクションを実行した後、その結果をLLMにフィードバックして、さらにアクションが必要かどうか、または終了してもよいかどうかを判断します。これはしばしば[ツール呼び出し](https://python.langchain.com/docs/concepts/tool_calling/)を介して達成されます。\n",
    "\n",
    "このチュートリアルでは、検索エンジンと対話できるエージェントを構築します。このエージェントに質問をし、検索ツールを呼び出す様子を見て、それと会話することができます。\n",
    "\n",
    "[Build an Agent \\| 🦜️🔗 LangChain](https://python.langchain.com/docs/tutorials/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e404eaee-0fc0-4a1d-96b9-ce2b1cf5aee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エンドツーエンドのエージェント\n",
    "以下のコードスニペットは、使用するツールを決定するためにLLMを使用する完全に機能するエージェントを表しています。これは汎用の検索ツールを備えています。会話のメモリを持っており、マルチターンのチャットボットとして使用できます。\n",
    "\n",
    "ガイドの残りの部分では、個々のコンポーネントと各部分の役割について説明しますが、すぐにコードを取得して始めたい場合は、自由に使用してください！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e269e22d-e005-485f-9fbd-99f8df923b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite langchain-openai mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86e9e614-b718-4939-8559-ec056211bf08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# MLflow Tracingの有効化\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2aef55-33c5-4499-9231-bf25b1fbbc9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(\"demo-token-takaaki.yayoi\", \"openai_api_key\")\n",
    "# TavilyのAPIキー\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2634328-835e-4735-940e-013f4efb35fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fee3d39c-cbdd-4df3-97b8-f9d0ef002a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 必要な機能をインポート\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "# メモリー\n",
    "memory = MemorySaver()\n",
    "# 言語モデル\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 検索ツール\n",
    "search = TavilySearchResults(max_results=2)\n",
    "# ツールセット\n",
    "tools = [search]\n",
    "# エージェントの作成\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac4eb44-0fff-4545-beba-1abbc2f6305f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0baabfbd-0ce0-4be4-9db9-87f9aad3bdbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## エージェントの実行\n",
    "\n",
    "エージェントが複数のステップを実行する場合、時間がかかることがあります。中間の進捗状況を表示するために、発生したメッセージをストリーミングバックすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44cc9417-a2a6-4a17-8011-a0cceb4fad44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# エージェントを使います\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"こんにちは、Takaです！私は東京に住んでいます。\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6af1a88-097d-4904-afac-1c3fd147ddb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"私が住んでいる場所の天気はどうですか？\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05c11dc0-07a3-460e-9e9f-3939b914ab9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## トークンのストリーミング\n",
    "\n",
    "メッセージをストリーミングバックするだけでなく、トークンをストリーミングバックすることも有用です。これを行うには、`stream_mode=\"messages\"`を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "305da94c-4752-4377-910b-7f0bc1cb20e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for step, metadata in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"東京の天気は？\")]},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
    "        print(text, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d3b7c2a-d848-4780-855b-8db81518d95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## まとめ\n",
    "\n",
    "これで終了です！このクイックスタートでは、シンプルなエージェントの作成方法を紹介しました。その後、応答をストリーミングバックする方法を示しました - 中間ステップだけでなく、トークンも含めて！さらに、会話を続けるためのメモリも追加しました。エージェントは学ぶことがたくさんある複雑なトピックです！\n",
    "\n",
    "エージェントに関する詳細情報は、[LangGraph](https://python.langchain.com/docs/concepts/architecture/#langgraph)のドキュメントを参照してください。独自の概念、チュートリアル、およびハウツーガイドが含まれています。"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "5. エージェントの構築",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
