{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21978468-aedc-4d7b-ae97-a2d84b5e5427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# チャットボットの構築\n",
    "\n",
    "[Build a Chatbot \\| 🦜️🔗 LangChain](https://python.langchain.com/docs/tutorials/chatbot/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f71af670-1503-4dde-bd18-d5cce823079b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 概要\n",
    "LLMを活用したチャットボットの設計と実装の例を紹介します。このチャットボットは会話を行い、[チャットモデル](https://python.langchain.com/docs/concepts/chat_models/)を使用して以前のやり取りを記憶することができます。\n",
    "\n",
    "このチャットボットは会話を行うために言語モデルのみを使用することに注意してください。他にも関連する概念がいくつかあります:\n",
    "\n",
    "- [Conversational RAG](https://python.langchain.com/docs/tutorials/qa_chat_history/): 外部データソースを使用してチャットボット体験を提供\n",
    "- [エージェント](https://python.langchain.com/docs/tutorials/agents/): アクションを実行できるチャットボットを構築\n",
    "\n",
    "このチュートリアルでは、これらの2つのより高度なトピックに役立つ基本をカバーしますが、必要に応じて直接そちらに進んでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef372452-6b86-430a-a70c-b4b322a6fac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain[openai] langgraph mlflow\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e76a0f-5fc3-4dab-b905-703e282a4b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# MLflow Tracingの有効化\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "072c253e-b071-4d81-a630-db7801e66a3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(\"demo-token-takaaki.yayoi\", \"openai_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcd256e5-32eb-428a-89e5-5ea45c33a163",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## クイックスタート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "341fee94-ce2e-4e8d-a43a-00648a15847e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbd3c402-510b-4b0e-892d-18fcc8ed08d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "まず、モデルを直接使用してみましょう。`ChatModel`はLangChainの「Runnable」のインスタンスであり、これらと対話するための標準インターフェースを提供します。モデルを単純に呼び出すには、メッセージのリストを`.invoke`メソッドに渡すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aef320b-2991-48ed-af5f-d5a8a226ca58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "model.invoke([HumanMessage(content=\"こんにちは！私はTakaです。\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9899951-6acd-49f5-addd-30f20209bee8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "モデル自体には状態の概念がありません。例えば、フォローアップの質問をすると："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f418a0cb-ddfb-4190-8dc5-9474a637685b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.invoke([HumanMessage(content=\"私の名前はなんですか？\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42d4a15c-0128-41cd-9278-d60fc1959c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "前の会話のターンを考慮せず、質問に答えることができないことがわかります。これはひどいチャットボット体験です！\n",
    "\n",
    "これを回避するために、[会話の履歴](https://python.langchain.com/docs/concepts/chat_history/)全体をモデルに渡す必要があります。そうするとどうなるか見てみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8e29e8-aef7-43cf-8ca5-38af0d871b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！私はTakaです。\"),\n",
    "        AIMessage(content=\"こんにちは、Takaさん！お会いできて嬉しいです。今日はどんなことをお話ししたいですか？\"),\n",
    "        HumanMessage(content=\"私の名前はなんですか？\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56037a9c-df85-457e-8cc7-573311f44ec7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**APIリファレンス**: [AIMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html)\n",
    "\n",
    "そして、良い応答が得られることがわかります！\n",
    "\n",
    "これがチャットボットが会話的にやり取りする能力の基本的な考え方です。では、これを最適に実装するにはどうすればよいでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f42e182-1d1f-4cea-8365-e4e1c1a75bf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## メッセージの永続化\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/)は組み込みの永続化レイヤーを実装しており、複数の会話ターンをサポートするチャットアプリケーションに最適です。\n",
    "\n",
    "チャットモデルを最小限のLangGraphアプリケーションでラップすることで、メッセージ履歴を自動的に永続化でき、マルチターンアプリケーションの開発が簡素化されます。\n",
    "\n",
    "LangGraphにはシンプルなインメモリチェックポインタが付属しており、以下で使用します。詳細については[ドキュメント](https://langchain-ai.github.io/langgraph/concepts/persistence/)を参照してください。異なる永続化バックエンド（例：SQLiteやPostgres）の使用方法も含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e3c4242-d445-4089-916f-b2d91300ab81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# 新しいグラフを定義\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# モデルを呼び出す関数を定義\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# グラフにノードを追加\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# メモリを追加\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8d8a4d-db78-4908-aa00-d27fc07c5f25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16894c1b-9d23-4287-be4a-ae4453ace13d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**APIリファレンス:** [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver) | [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph)\n",
    "\n",
    "次に、毎回runnableに渡す構成情報を作成する必要があります。この構成には、入力の一部ではないが依然として有用な情報が含まれています。この場合、`thread_id`を含めたいと考えています。これは次のようになります:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c33f9069-b7aa-4944-afb0-9aa64ec4d410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bf1737b-ef5f-40da-b6b9-b97140f52280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "これにより、単一のアプリケーションで複数の会話スレッドをサポートできるようになり、アプリケーションに複数のユーザーがいる場合によくある要件に対応できます。\n",
    "\n",
    "次に、アプリケーションを呼び出すことができます:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c79010f0-458c-4e85-ae91-289a9763a2df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"こんにちは！私はTakaです。\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # 出力には状態内のすべてのメッセージが含まれています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8583a416-aec1-496c-9dd4-27c49f767a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"私の名前はなんですか？\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a23ec4b-5aae-4e1f-8f46-bfdc25523f2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "素晴らしい！私たちのチャットボットは、私たちについての情報を覚えています。構成を変更して別の`thread_id`を参照するようにすると、新しい会話が始まることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aaa9414-a506-4605-9f62-d00eb8a689ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88ec8f09-a4e4-4247-9a52-5982e9c1817a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "しかし、（データベースに保存しているため）元の会話に戻ることはいつでも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7011a501-3573-45d9-80c1-5b0ff0ca5f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d580fc1-4e56-42ea-adfe-9bb3d4ce8341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "これが、複数のユーザーとの会話をサポートするチャットボットの方法です！\n",
    "\n",
    "現在、私たちが行ったのは、モデルの周りに単純な永続化レイヤーを追加しただけです。プロンプトテンプレートを追加することで、チャットボットをより複雑でパーソナライズされたものにすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc845bae-a193-4c13-95fd-0abdc1b815e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## プロンプトテンプレート\n",
    "\n",
    "[プロンプトテンプレート](https://python.langchain.com/docs/concepts/prompt_templates/)は、生のユーザー情報をLLMが処理できる形式に変換するのに役立ちます。この場合、生のユーザー入力はメッセージだけであり、それをLLMに渡しています。これを少し複雑にしてみましょう。まず、カスタム指示を含むシステムメッセージを追加します（ただし、入力としてメッセージを受け取ります）。次に、メッセージ以外の入力も追加します。\n",
    "\n",
    "システムメッセージを追加するために、`ChatPromptTemplate`を作成します。`MessagesPlaceholder`を利用して、すべてのメッセージを渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21a84112-673e-4113-9bfc-a524b67c2497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"あなたは海賊のように話します。できる限りの質問に答えてください。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a524eba-684c-4f72-b0ad-efe39ac86eef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**APIリファレンス:** [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [MessagesPlaceholder](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n",
    "\n",
    "アプリケーションを更新してこのテンプレートを組み込みましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "417d5e66-0d72-47b2-8270-24b72fd3265f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33aa21e2-eb0d-4f8f-8787-6df8cd7c53fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "同じ方法でアプリケーションを呼び出します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4e4dffc-2a77-4436-822e-f74f44bdd2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"はい！私はYayoiです。\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59039395-3c33-406a-8939-32ad0d983375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"私の名前は？\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b27320a5-1f84-4ec0-99b4-8c93407c4009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "素晴らしい！プロンプトをもう少し複雑にしてみましょう。プロンプトテンプレートが次のようになったと仮定しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bdd7dcd-2036-4f4d-a2a6-ebfe19a3e647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"あなたは役に立つアシスタントです。{language}で可能な限りの力を尽くしてすべての質問に答えます。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a7a4528-3d29-4b67-95c0-7ed6d9a0bc5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "プロンプトに新しい入力`language`を追加したことに注意してください。アプリケーションには今や2つのパラメーター、入力`message`と`language`があります。この変更を反映するために、アプリケーションの状態を更新する必要があります："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "622be463-6e53-4d88-b4e5-162cd5fde890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98604cdf-9a16-44d4-9c81-239cd429f1cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"はい、私はBobです。\"\n",
    "language = \"英語\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b1117bf-cef1-4558-839c-d51a4c1f64cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "全体の状態が保持されるため、変更が必要ない場合は、`language`のようなパラメーターを省略できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a623df24-ef51-4004-9ece-907642e9d00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4638164-d4bc-4abf-b626-9b19f8b68e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 会話履歴の管理\n",
    "\n",
    "チャットボットを構築する際に理解すべき重要な概念の一つは、会話履歴の管理方法です。管理されないままにしておくと、メッセージのリストが無制限に増加し、LLMのコンテキストウィンドウをオーバーフローする可能性があります。したがって、渡すメッセージのサイズを制限するステップを追加することが重要です。\n",
    "\n",
    "**重要なのは、メッセージ履歴から以前のメッセージを読み込んだ後、そしてプロンプトテンプレートの前にメッセージの制限処理を行うことです。**\n",
    "\n",
    "これを行うために、プロンプトの前に`messages`のキーを適切に修正する簡単なステップを追加し、その新しいチェーンをメッセージ履歴クラスでラップします。\n",
    "\n",
    "LangChainには、[メッセージのリストを管理](https://python.langchain.com/docs/how_to/#messages)するためのいくつかの組み込みヘルパーが付属しています。この場合、モデルに送信するメッセージの数を減らすために[trim\\_messages](https://python.langchain.com/docs/how_to/trim_messages/)ヘルパーを使用します。トリマーでは、保持したいトークンの数や、システムメッセージを常に保持するかどうか、部分的なメッセージを許可するかどうかなどのパラメーターを指定できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777b7752-391d-4c91-8710-57cf85c10f84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"あなたは良いアシスタントです\"),\n",
    "    HumanMessage(content=\"こんにちは！私はボブです\"),\n",
    "    AIMessage(content=\"こんにちは！\"),\n",
    "    HumanMessage(content=\"私はバニラアイスクリームが好きです\"),\n",
    "    AIMessage(content=\"いいですね\"),\n",
    "    HumanMessage(content=\"2 + 2 は何ですか\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"ありがとう\"),\n",
    "    AIMessage(content=\"どういたしまして！\"),\n",
    "    HumanMessage(content=\"楽しんでいますか？\"),\n",
    "    AIMessage(content=\"はい！\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c6e7bff-d20a-4672-aa62-6bd83430301e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "チェーンで使用するには、`messages`入力をプロンプトに渡す前にトリマーを実行するだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ccac80-91be-4b3c-9cc8-48ce1b1ee67e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75071975-2ca3-4139-84cb-0df108f8f5d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "今、モデルに名前を尋ねても、チャット履歴のその部分がトリミングされているため、モデルはそれを知りません："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc845ddb-bbfa-42f2-81fa-f3a82f4daf33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"私の名前は？\"\n",
    "language = \"日本語\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81e5097d-9713-402e-b4d0-6be58a2087a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "しかし、直近の数件のメッセージ内の情報について尋ねると、それを覚えています："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67cd3fb1-0e78-4fa3-98d3-563362a975e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
    "query = \"私が質問した感情の質問は何？\"\n",
    "language = \"日本語\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f34398d7-fd3c-4545-b3e8-67746d2d11c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ストリーミング\n",
    "\n",
    "これで動作するチャットボットを手に入れました。ただし、チャットボットアプリケーションの非常に重要なUXの考慮事項の1つは、ストリーミングです。LLMは応答するのに時間がかかることがありますので、ユーザーエクスペリエンスを向上させるために、ほとんどのアプリケーションが行うことの1つは、生成されるトークンごとにストリームバックすることです。これにより、ユーザーは進捗状況を確認できます。\n",
    "\n",
    "実際、これを行うのは非常に簡単です！\n",
    "\n",
    "デフォルトでは、LangGraphアプリケーションの`.stream`はアプリケーションステップをストリーム化します-- この場合、モデル応答の単一ステップです。`stream_mode=\"messages\"`を設定すると、出力トークンをストリーム化できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe0f9fdc-1afa-46be-9407-10a9b4a1abc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"はい、私はToddです。ジョークを教えてください。\"\n",
    "language = \"日本語\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # モデルのレスポンスのみにフィルタリング\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2dfa589-efe1-4cb3-b2b7-98a3b636b7a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "3. チャットボットの構築",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
